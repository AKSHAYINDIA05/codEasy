<!DOCTYPE html>
<html>
<head>
  <title>#codEasy</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="copyfunc.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <script src="copyfunc.js"></script>
  <style>
  body {
    position: relative; 
  }
  #P1 {margin-top:100px;padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P2 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P3 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P4 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P5 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P6 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P7 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P8 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P9 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P10 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P11 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P12 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P13 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  /* #P14 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P15 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P16 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P17 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P18 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P19 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P20 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P21 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P22 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P23 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P24 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P25 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);}
  #P26 {padding-top:25px;height:auto;color: #fff; background: linear-gradient(35deg, #585454, #333333);} */
  </style>
</head>
<body>

<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container-fluid">
    <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>                        
      </button>
      <p class="navbar-brand" style="color: white;"><a href="index.html"><i class="fa fa-home" style="font-size:20px"></i></a>&nbsp;&nbsp;<a  href="python.html" style="text-decoration: none;"><i href="python.html" class="fa fa-chevron-circle-left" style="font-size: 20px;"></i>&nbsp;&nbsp;Go Back</a>&nbsp;&nbsp;</p>
    </div>
    <div>
      <div class="collapse navbar-collapse" id="myNavbar">
        <ul class="nav navbar-nav">
          <li><a href="#P1">P 1</a></li>
          <li><a href="#P2">P 2</a></li>
          <li><a href="#P3">P 3</a></li>
          <li><a href="#P4">P 4</a></li>
          <li><a href="#P5">P 5</a></li>
          <li><a href="#P6">P 6</a></li>
          <li><a href="#P7">P 7</a></li>
          <li><a href="#P8">P 8</a></li>
          <li><a href="#P9">P 9</a></li>
          <li><a href="#P10">P 10</a></li>
          <li><a href="#P11">P 11</a></li>
          <li><a href="#P12">P 12</a></li>
          <li><a href="#P13">P 13</a></li>
          <!-- <li><a href="#P14">P 14</a></li>
          <li><a href="#P15">P 15</a></li>
          <li><a href="#P16">P 16</a></li>
          <li><a href="#P17">P 17</a></li>
          <li><a href="#P18">P 18</a></li>
          <li><a href="#P19">P 19</a></li>
          <li><a href="#P20">P 20</a></li>
          <li><a href="#P21">P 21</a></li>
          <li><a href="#P22">P 22</a></li>
          <li><a href="#P23">P 23</a></li>
          <li><a href="#P24">P 24</a></li>
          <li><a href="#P25">P 25</a></li>
          <li><a href="#P26">P 26</a></li> -->
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </div>
</nav>  
<div id="P1" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 1</h3><button onclick="copyToClipboard('#P1')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        FACE DETECTION 
      import cv2
      import mediapipe as mp
      mp_face_detection = mp.solutions.face_detection
      mp_drawing = mp.solutions.drawing_utils
      
      # For static images:
      IMAGE_FILES = []
      with mp_face_detection.FaceDetection(
          model_selection=1, min_detection_confidence=0.5) as face_detection:
        for idx, file in enumerate(IMAGE_FILES):
          image = cv2.imread(file)
          # Convert the BGR image to RGB and process it with MediaPipe Face Detection.
          results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          # Draw face detections of each face.
          if not results.detections:
            continue
          annotated_image = image.copy()
          for detection in results.detections:
            print('Nose tip:')
            print(mp_face_detection.get_key_point(
                detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))
            mp_drawing.draw_detection(annotated_image, detection)
          cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)
      
      # For webcam input:
      cap = cv2.VideoCapture(0)
      with mp_face_detection.FaceDetection(
          model_selection=0, min_detection_confidence=0.5) as face_detection:
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
          results = face_detection.process(image)
      
          # Draw the face detection annotations on the image.
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
          if results.detections:
            for detection in results.detections:
              mp_drawing.draw_detection(image, detection)
          # Flip the image horizontally for a selfie-view display.
          cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P2" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 2</h3><button onclick="copyToClipboard('#P2')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        FACE MESH
      import cv2
      import mediapipe as mp
      mp_drawing = mp.solutions.drawing_utils
      mp_drawing_styles = mp.solutions.drawing_styles
      mp_face_mesh = mp.solutions.face_mesh
      
      # For static images:
      IMAGE_FILES = []
      drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)
      with mp_face_mesh.FaceMesh(
          static_image_mode=True,
          max_num_faces=1,
          refine_landmarks=True,
          min_detection_confidence=0.5) as face_mesh:
        for idx, file in enumerate(IMAGE_FILES):
          image = cv2.imread(file)
          # Convert the BGR image to RGB before processing.
          results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          # Print and draw face mesh landmarks on the image.
          if not results.multi_face_landmarks:
            continue
          annotated_image = image.copy()
          for face_landmarks in results.multi_face_landmarks:
            print('face_landmarks:', face_landmarks)
            mp_drawing.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_TESSELATION,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_drawing_styles
                .get_default_face_mesh_tesselation_style())
            mp_drawing.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_CONTOURS,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_drawing_styles
                .get_default_face_mesh_contours_style())
            mp_drawing.draw_landmarks(
                image=annotated_image,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_IRISES,
                landmark_drawing_spec=None,
                connection_drawing_spec=mp_drawing_styles
                .get_default_face_mesh_iris_connections_style())
          cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)
      
      # For webcam input:
      drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)
      cap = cv2.VideoCapture(0)
      with mp_face_mesh.FaceMesh(
          max_num_faces=1,
          refine_landmarks=True,
          min_detection_confidence=0.5,
          min_tracking_confidence=0.5) as face_mesh:
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
          results = face_mesh.process(image)
      
          # Draw the face mesh annotations on the image.
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
          if results.multi_face_landmarks:
            for face_landmarks in results.multi_face_landmarks:
              mp_drawing.draw_landmarks(
                  image=image,
                  landmark_list=face_landmarks,
                  connections=mp_face_mesh.FACEMESH_TESSELATION,
                  landmark_drawing_spec=None,
                  connection_drawing_spec=mp_drawing_styles
                  .get_default_face_mesh_tesselation_style())
              mp_drawing.draw_landmarks(
                  image=image,
                  landmark_list=face_landmarks,
                  connections=mp_face_mesh.FACEMESH_CONTOURS,
                  landmark_drawing_spec=None,
                  connection_drawing_spec=mp_drawing_styles
                  .get_default_face_mesh_contours_style())
              mp_drawing.draw_landmarks(
                  image=image,
                  landmark_list=face_landmarks,
                  connections=mp_face_mesh.FACEMESH_IRISES,
                  landmark_drawing_spec=None,
                  connection_drawing_spec=mp_drawing_styles
                  .get_default_face_mesh_iris_connections_style())
          # Flip the image horizontally for a selfie-view display.
          cv2.imshow('MediaPipe Face Mesh', cv2.flip(image, 1))
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P3" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 3</h3><button onclick="copyToClipboard('#P3')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        PALM DETECTION
      import cv2
      import mediapipe as mp
      mp_drawing = mp.solutions.drawing_utils
      mp_drawing_styles = mp.solutions.drawing_styles
      mp_hands = mp.solutions.hands
      
      # For static images:
      IMAGE_FILES = []
      with mp_hands.Hands(
          static_image_mode=True,
          max_num_hands=2,
          min_detection_confidence=0.5) as hands:
        for idx, file in enumerate(IMAGE_FILES):
          # Read an image, flip it around y-axis for correct handedness output (see
          # above).
          image = cv2.flip(cv2.imread(file), 1)
          # Convert the BGR image to RGB before processing.
          results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          # Print handedness and draw hand landmarks on the image.
          print('Handedness:', results.multi_handedness)
          if not results.multi_hand_landmarks:
            continue
          image_height, image_width, _ = image.shape
          annotated_image = image.copy()
          for hand_landmarks in results.multi_hand_landmarks:
            print('hand_landmarks:', hand_landmarks)
            print(
                f'Index finger tip coordinates: (',
                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * image_width}, '
                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * image_height})'
            )
            mp_drawing.draw_landmarks(
                annotated_image,
                hand_landmarks,
                mp_hands.HAND_CONNECTIONS,
                mp_drawing_styles.get_default_hand_landmarks_style(),
                mp_drawing_styles.get_default_hand_connections_style())
          cv2.imwrite(
              '/tmp/annotated_image' + str(idx) + '.png', cv2.flip(annotated_image, 1))
          # Draw hand world landmarks.
          if not results.multi_hand_world_landmarks:
            continue
          for hand_world_landmarks in results.multi_hand_world_landmarks:
            mp_drawing.plot_landmarks(
              hand_world_landmarks, mp_hands.HAND_CONNECTIONS, azimuth=5)
      
      # For webcam input:
      cap = cv2.VideoCapture(0)
      with mp_hands.Hands(
          model_complexity=0,
          min_detection_confidence=0.5,
          min_tracking_confidence=0.5) as hands:
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
          results = hands.process(image)
      
          # Draw the hand annotations on the image.
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
          if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
              mp_drawing.draw_landmarks(
                  image,
                  hand_landmarks,
                  mp_hands.HAND_CONNECTIONS,
                  mp_drawing_styles.get_default_hand_landmarks_style(),
                  mp_drawing_styles.get_default_hand_connections_style())
          # Flip the image horizontally for a selfie-view display.
          cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P4" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 4</h3><button onclick="copyToClipboard('#P4')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        POSE SEGMENTATION MASK
      import cv2
      import mediapipe as mp
      mp_drawing = mp.solutions.drawing_utils
      mp_drawing_styles = mp.solutions.drawing_styles
      mp_pose = mp.solutions.pose
      
      # For static images:
      IMAGE_FILES = []
      BG_COLOR = (192, 192, 192) # gray
      with mp_pose.Pose(
          static_image_mode=True,
          model_complexity=2,
          enable_segmentation=True,
          min_detection_confidence=0.5) as pose:
        for idx, file in enumerate(IMAGE_FILES):
          image = cv2.imread(file)
          image_height, image_width, _ = image.shape
          # Convert the BGR image to RGB before processing.
          results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          if not results.pose_landmarks:
            continue
          print(
              f'Nose coordinates: ('
              f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * image_width}, '
              f'{results.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].y * image_height})'
          )
      
          annotated_image = image.copy()
          # Draw segmentation on the image.
          # To improve segmentation around boundaries, consider applying a joint
          # bilateral filter to "results.segmentation_mask" with "image".
          condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1
          bg_image = np.zeros(image.shape, dtype=np.uint8)
          bg_image[:] = BG_COLOR
          annotated_image = np.where(condition, annotated_image, bg_image)
          # Draw pose landmarks on the image.
          mp_drawing.draw_landmarks(
              annotated_image,
              results.pose_landmarks,
              mp_pose.POSE_CONNECTIONS,
              landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())
          cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)
          # Plot pose world landmarks.
          mp_drawing.plot_landmarks(
              results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)
      
      # For webcam input:
      cap = cv2.VideoCapture(0)
      with mp_pose.Pose(
          min_detection_confidence=0.5,
          min_tracking_confidence=0.5) as pose:
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
          results = pose.process(image)
      
          # Draw the pose annotation on the image.
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
          mp_drawing.draw_landmarks(
              image,
              results.pose_landmarks,
              mp_pose.POSE_CONNECTIONS,
              landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())
          # Flip the image horizontally for a selfie-view display.
          cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P5" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 5</h3><button onclick="copyToClipboard('#P5')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        HOLISTIC PIPELINE 
      import cv2
      import mediapipe as mp
      mp_drawing = mp.solutions.drawing_utils
      mp_drawing_styles = mp.solutions.drawing_styles
      mp_holistic = mp.solutions.holistic
      
      # For static images:
      IMAGE_FILES = []
      with mp_holistic.Holistic(
          static_image_mode=True,
          model_complexity=2,
          enable_segmentation=True,
          refine_face_landmarks=True) as holistic:
        for idx, file in enumerate(IMAGE_FILES):
          image = cv2.imread(file)
          image_height, image_width, _ = image.shape
          # Convert the BGR image to RGB before processing.
          results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          if results.pose_landmarks:
            print(
                f'Nose coordinates: ('
                f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '
                f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_height})'
            )
      
          annotated_image = image.copy()
          # Draw segmentation on the image.
          # To improve segmentation around boundaries, consider applying a joint
          # bilateral filter to "results.segmentation_mask" with "image".
          condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1
          bg_image = np.zeros(image.shape, dtype=np.uint8)
          bg_image[:] = BG_COLOR
          annotated_image = np.where(condition, annotated_image, bg_image)
          # Draw pose, left and right hands, and face landmarks on the image.
          mp_drawing.draw_landmarks(
              annotated_image,
              results.face_landmarks,
              mp_holistic.FACEMESH_TESSELATION,
              landmark_drawing_spec=None,
              connection_drawing_spec=mp_drawing_styles
              .get_default_face_mesh_tesselation_style())
          mp_drawing.draw_landmarks(
              annotated_image,
              results.pose_landmarks,
              mp_holistic.POSE_CONNECTIONS,
              landmark_drawing_spec=mp_drawing_styles.
              get_default_pose_landmarks_style())
          cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)
          # Plot pose world landmarks.
          mp_drawing.plot_landmarks(
              results.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS)
      
      # For webcam input:
      cap = cv2.VideoCapture(0)
      with mp_holistic.Holistic(
          min_detection_confidence=0.5,
          min_tracking_confidence=0.5) as holistic:
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
          results = holistic.process(image)
      
          # Draw landmark annotation on the image.
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
          mp_drawing.draw_landmarks(
              image,
              results.face_landmarks,
              mp_holistic.FACEMESH_CONTOURS,
              landmark_drawing_spec=None,
              connection_drawing_spec=mp_drawing_styles
              .get_default_face_mesh_contours_style())
          mp_drawing.draw_landmarks(
              image,
              results.pose_landmarks,
              mp_holistic.POSE_CONNECTIONS,
              landmark_drawing_spec=mp_drawing_styles
              .get_default_pose_landmarks_style())
          # Flip the image horizontally for a selfie-view display.
          cv2.imshow('MediaPipe Holistic', cv2.flip(image, 1))
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P6" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 6</h3><button onclick="copyToClipboard('#P6')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        SELFIE SEGMENTATION
      import cv2
      import mediapipe as mp
      import numpy as np
      mp_drawing = mp.solutions.drawing_utils
      mp_selfie_segmentation = mp.solutions.selfie_segmentation
      
      # For static images:
      IMAGE_FILES = []
      BG_COLOR = (192, 192, 192) # gray
      MASK_COLOR = (255, 255, 255) # white
      with mp_selfie_segmentation.SelfieSegmentation(
          model_selection=0) as selfie_segmentation:
        for idx, file in enumerate(IMAGE_FILES):
          image = cv2.imread(file)
          image_height, image_width, _ = image.shape
          # Convert the BGR image to RGB before processing.
          results = selfie_segmentation.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          # Draw selfie segmentation on the background image.
          # To improve segmentation around boundaries, consider applying a joint
          # bilateral filter to "results.segmentation_mask" with "image".
          condition = np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1
          # Generate solid color images for showing the output selfie segmentation mask.
          fg_image = np.zeros(image.shape, dtype=np.uint8)
          fg_image[:] = MASK_COLOR
          bg_image = np.zeros(image.shape, dtype=np.uint8)
          bg_image[:] = BG_COLOR
          output_image = np.where(condition, fg_image, bg_image)
          cv2.imwrite('/tmp/selfie_segmentation_output' + str(idx) + '.png', output_image)
      
      # For webcam input:
      BG_COLOR = (192, 192, 192) # gray
      cap = cv2.VideoCapture(0)
      with mp_selfie_segmentation.SelfieSegmentation(
          model_selection=1) as selfie_segmentation:
        bg_image = None
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # Flip the image horizontally for a later selfie-view display, and convert
          # the BGR image to RGB.
          image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          results = selfie_segmentation.process(image)
      
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
      
          # Draw selfie segmentation on the background image.
          # To improve segmentation around boundaries, consider applying a joint
          # bilateral filter to "results.segmentation_mask" with "image".
          condition = np.stack(
            (results.segmentation_mask,) * 3, axis=-1) > 0.1
          # The background can be customized.
          #   a) Load an image (with the same width and height of the input image) to
          #      be the background, e.g., bg_image = cv2.imread('/path/to/image/file')
          #   b) Blur the input image by applying image filtering, e.g.,
          #      bg_image = cv2.GaussianBlur(image,(55,55),0)
          if bg_image is None:
            bg_image = np.zeros(image.shape, dtype=np.uint8)
            bg_image[:] = BG_COLOR
          output_image = np.where(condition, image, bg_image)
      
          cv2.imshow('MediaPipe Selfie Segmentation', output_image)
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P7" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 7</h3><button onclick="copyToClipboard('#P7')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                               OBJECTRON(3D OBJECT DETECTION)     
      import cv2
      import mediapipe as mp
      mp_drawing = mp.solutions.drawing_utils
      mp_objectron = mp.solutions.objectron
      
      # For static images:
      IMAGE_FILES = []
      with mp_objectron.Objectron(static_image_mode=True,
                                  max_num_objects=5,
                                  min_detection_confidence=0.5,
                                  model_name='Shoe') as objectron:
        for idx, file in enumerate(IMAGE_FILES):
          image = cv2.imread(file)
          # Convert the BGR image to RGB and process it with MediaPipe Objectron.
          results = objectron.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
      
          # Draw box landmarks.
          if not results.detected_objects:
            print(f'No box landmarks detected on {file}')
            continue
          print(f'Box landmarks of {file}:')
          annotated_image = image.copy()
          for detected_object in results.detected_objects:
            mp_drawing.draw_landmarks(
                annotated_image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)
            mp_drawing.draw_axis(annotated_image, detected_object.rotation,
                                 detected_object.translation)
            cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)
      
      # For webcam input:
      cap = cv2.VideoCapture(0)
      with mp_objectron.Objectron(static_image_mode=False,
                                  max_num_objects=5,
                                  min_detection_confidence=0.5,
                                  min_tracking_confidence=0.99,
                                  model_name='Shoe') as objectron:
        while cap.isOpened():
          success, image = cap.read()
          if not success:
            print("Ignoring empty camera frame.")
            # If loading a video, use 'break' instead of 'continue'.
            continue
      
          # To improve performance, optionally mark the image as not writeable to
          # pass by reference.
          image.flags.writeable = False
          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
          results = objectron.process(image)
      
          # Draw the box landmarks on the image.
          image.flags.writeable = True
          image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
          if results.detected_objects:
              for detected_object in results.detected_objects:
                  mp_drawing.draw_landmarks(
                    image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)
                  mp_drawing.draw_axis(image, detected_object.rotation,
                                       detected_object.translation)
          # Flip the image horizontally for a selfie-view display.
          cv2.imshow('MediaPipe Objectron', cv2.flip(image, 1))
          if cv2.waitKey(5) & 0xFF == 27:
            break
      cap.release()
      </strong>
    </strong></pre></p>
  </div>
<div id="P8" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 8</h3><button onclick="copyToClipboard('#P8')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        DIGITAL CLOCK
      from tkinter import Label, Tk 
      import time
      app_window = Tk() 
      app_window.title("Digital Clock") 
      app_window.geometry("420x150") 
      app_window.resizable(1,1)
      
      text_font= ("Boulder", 68, 'bold')
      background = "#f2e750"
      foreground= "#363529"
      border_width = 25
      
      label = Label(app_window, font=text_font, bg=background, fg=foreground, bd=border_width) 
      label.grid(row=0, column=1)
      
      def digital_clock(): 
         time_live = time.strftime("%H:%M:%S")
         label.config(text=time_live) 
         label.after(200, digital_clock)
      
      digital_clock()
      app_window.mainloop()</strong>
    </strong></pre></p>
  </div>
<div id="P9" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 9</h3><button onclick="copyToClipboard('#P9')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                        MUSIC PLAYER GUI
      import pygame
      import tkinter as tkr
      from tkinter.filedialog import askdirectory
      import os
      
      music_player = tkr.Tk()
      music_player.title("My Music Player")
      music_player.geometry("450x350")
      directory = askdirectory()
      os.chdir(directory)
      song_list = os.listdir()
      
      play_list = tkr.Listbox(music_player, font="Helvetica 12 bold", bg='yellow', selectmode=tkr.SINGLE)
      for item in song_list:
          pos = 0
          play_list.insert(pos, item)
          pos += 1
      pygame.init()
      pygame.mixer.init()
      
      def play():
          pygame.mixer.music.load(play_list.get(tkr.ACTIVE))
          var.set(play_list.get(tkr.ACTIVE))
          pygame.mixer.music.play()
      def stop():
          pygame.mixer.music.stop()
      def pause():
          pygame.mixer.music.pause()
      def unpause():
          pygame.mixer.music.unpause()
      Button1 = tkr.Button(music_player, width=5, height=3, font="Helvetica 12 bold", text="PLAY", command=play, bg="blue", fg="white")
      Button2 = tkr.Button(music_player, width=5, height=3, font="Helvetica 12 bold", text="STOP", command=stop, bg="red", fg="white")
      Button3 = tkr.Button(music_player, width=5, height=3, font="Helvetica 12 bold", text="PAUSE", command=pause, bg="purple", fg="white")
      Button4 = tkr.Button(music_player, width=5, height=3, font="Helvetica 12 bold", text="UNPAUSE", command=unpause, bg="orange", fg="white")
      
      var = tkr.StringVar()
      song_title = tkr.Label(music_player, font="Helvetica 12 bold", textvariable=var)
      
      song_title.pack()
      Button1.pack(fill="x")
      Button2.pack(fill="x")
      Button3.pack(fill="x")
      Button4.pack(fill="x")
      play_list.pack(fill="both", expand="yes")
      music_player.mainloop()</strong>
    </strong></pre></p>
  </div>
<div id="P10" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 10</h3><button onclick="copyToClipboard('#P10')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                    COVID-19 TELEGRAM BOT
      import requests
      import json
      def summary(update, context):
          response = requests.get('https://api.covid19api.com/summary')
          if(response.status_code==200): #Everything went okay, we have the data
              data = response.json()
              print(data['Global'])
              context.bot.send_message(chat_id=update.effective_chat.id, text=data['Global'])
          else: #something went wrong
              context.bot.send_message(chat_id=update.effective_chat.id, text="Error, something went wrong.")
      ​
      corona_summary_handler = CommandHandler('summary', summary)
      dispatcher.add_handler(corona_summary_handler)</strong>
    </strong></pre></p>
  </div>
<div id="P11" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 11</h3><button onclick="copyToClipboard('#P11')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                  OTP VERIFICATION
      import os
      import math
      import random
      import smtplib
      
      digits="0123456789"
      OTP=""
      for i in range(6):
          OTP+=digits[math.floor(random.random()*10)]
      otp = OTP + " is your OTP"
      msg= otp
      s = smtplib.SMTP('smtp.gmail.com', 587)
      s.starttls()
      s.login("Your Gmail Account", "You app password")
      emailid = input("Enter your email: ")
      s.sendmail('&&&&&&&&&&&',emailid,msg)
      a = input("Enter Your OTP >>: ")
      if a == OTP:
          print("Verified")
      else:
          print("Please Check your OTP again")</strong>
    </strong></pre></p>
  </div>
<div id="P12" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 12</h3><button onclick="copyToClipboard('#P12')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                  PYTHON CALENDAR GUI
      #Importing tkinter module
      from tkinter import *
      #importing calendar module
      import calendar
      
      #function to show calendar of the given year
      def showCalender():
          gui = Tk()
          gui.config(background='grey')
          gui.title("Calender for the year")
          gui.geometry("550x600")
          year = int(year_field.get())
          gui_content= calendar.calendar(year)
          calYear = Label(gui, text= gui_content, font= "Consolas 10 bold")
          calYear.grid(row=5, column=1,padx=20)
          gui.mainloop()
          #Driver code
          if __name__=='__main__':
              new = Tk()
              new.config(background='grey')
              new.title("Calender")
              new.geometry("250x140")
              cal = Label(new, text="Calender",bg='grey',font=("times", 28, "bold"))
              year = Label(new, text="Enter year", bg='dark grey')
              year_field=Entry(new)
              button = Button(new, text='Show Calender',
          fg='Black',bg='Blue',command=showCalender)
          
              #putting widgets in position
              cal.grid(row=1, column=1)
              year.grid(row=2, column=1)
              year_field.grid(row=3, column=1)
              button.grid(row=4, column=1)
              Exit.grid(row=6, column=1)
              new.mainloop()</strong>
    </strong></pre></p>
  </div>
<div id="P13" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 13</h3><button onclick="copyToClipboard('#P13')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
                                  ANALOG CLOCK 
      try:
      import Tkinter
    except:
      import tkinter as Tkinter
    
    import math	# Required For Coordinates Calculation
    import time	# Required For Time Handling
    #
    #
    # class
    class main(Tkinter.Tk):
      def __init__(self):
        Tkinter.Tk.__init__(self)
        self.x=150	# Center Point x
        self.y=150	# Center Point
        self.length=50	# Stick Length
        self.creating_all_function_trigger()
    
      # Creating Trigger For Other Functions
      def creating_all_function_trigger(self):
        self.create_canvas_for_shapes()
        self.creating_background_()
        self.creating_sticks()
        return
    
      # Creating Background
      def creating_background_(self):
        self.image=Tkinter.PhotoImage(file='clock.gif')
        self.canvas.create_image(150,150, image=self.image)
        return
    
      # creating Canvas
      def create_canvas_for_shapes(self):
        self.canvas=Tkinter.Canvas(self, bg='black')
        self.canvas.pack(expand='yes',fill='both')
        return
    
      # Creating Moving Sticks
      def creating_sticks(self):
        self.sticks=[]
        for i in range(3):
          store=self.canvas.create_line(self.x, self.y,self.x+self.length,self.y+self.length,width=2, fill='red')
          self.sticks.append(store)
        return
    
      # Function Need Regular Update
      def update_class(self):
        now=time.localtime()
        t = time.strptime(str(now.tm_hour), "%H")
        hour = int(time.strftime( "%I", t ))*5
        now=(hour,now.tm_min,now.tm_sec)
        # Changing Stick Coordinates
        for n,i in enumerate(now):
          x,y=self.canvas.coords(self.sticks[n])[0:2]
          cr=[x,y]
          cr.append(self.length*math.cos(math.radians(i*6)-math.radians(90))+self.x)
          cr.append(self.length*math.sin(math.radians(i*6)-math.radians(90))+self.y)
          self.canvas.coords(self.sticks[n], tuple(cr))
        return
    
    # Main Function Trigger
    if __name__ == '__main__':
      root = main()
    
      # Creating Main Loop
      while True:
        root.update()
        root.update_idletasks()
        root.update_class()</strong>
    </strong></pre></p>
  </div>
<!-- <div id="P14" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 14</h3><button onclick="copyToClipboard('#P14')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P15" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 15</h3><button onclick="copyToClipboard('#P15')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P16" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 16</h3><button onclick="copyToClipboard('#P16')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P17" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 17</h3><button onclick="copyToClipboard('#P17')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P18" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 18</h3><button onclick="copyToClipboard('#P18')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P19" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 19</h3><button onclick="copyToClipboard('#P19')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P20" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 20</h3><button onclick="copyToClipboard('#P20')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P21" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 21</h3><button onclick="copyToClipboard('#P21')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P22" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 22</h3><button onclick="copyToClipboard('#P22')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P23" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 23</h3><button onclick="copyToClipboard('#P23')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P24" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 24</h3><button onclick="copyToClipboard('#P24')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P25" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 25</h3><button onclick="copyToClipboard('#P25')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div>
<div id="P26" class="container-fluid">
    <h3 style="font-family: Cambria, Cochin, Georgia, Times, 'Times New Roman', serif;">PROGRAM 26</h3><button onclick="copyToClipboard('#P26')">Copy</button>
    <p><pre style="background:linear-gradient(45deg, #bfc0d2, solid black);color: solid black; font-size: 30px;"><strong>
    </strong>
    </strong></pre></p>
  </div> -->
  <script>
    $(document).ready(function(){
      // Add scrollspy to <body>
      $('body').scrollspy({target: ".navbar", offset: 50});   
    
      // Add smooth scrolling on all links inside the navbar
      $("#myNavbar a").on('click', function(event) {
        // Make sure this.hash has a value before overriding default behavior
        if (this.hash !== "") {
          // Prevent default anchor click behavior
          event.preventDefault();
    
          // Store hash
          var hash = this.hash;
    
          // Using jQuery's animate() method to add smooth page scroll
          // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
          $('html, body').animate({
            scrollTop: $(hash).offset().top
          }, 800, function(){
       
            // Add hash (#) to URL when done scrolling (default click behavior)
            window.location.hash = hash;
          });
        }  // End if
      });
    });
    </script>
    
    </body>
    </html>